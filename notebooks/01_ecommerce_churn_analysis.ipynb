{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de Churn E-Commerce et Pr√©diction Client\n",
    "\n",
    "## Contexte Business\n",
    "Ce notebook analyse le comportement des clients d'une plateforme e-commerce pour **pr√©dire le churn** (r√©siliation d'abonnement) et identifier les facteurs de risque. L'objectif est de fournir des insights actionnables pour am√©liorer la r√©tention client.\n",
    "\n",
    "## Dataset\n",
    "- **Source** : E-Commerce Customer Insights and Churn Dataset 2025 (Kaggle)\n",
    "- **Taille** : 2000 clients, 17 variables\n",
    "- **Cible** : subscription_status (active, cancelled, paused)\n",
    "\n",
    "## Workflow\n",
    "1. Chargement et nettoyage des donn√©es\n",
    "2. Analyse exploratoire (EDA)\n",
    "3. Feature engineering et cr√©ation de la variable cible binaire\n",
    "4. Mod√©lisation (Logistic Regression, Random Forest)\n",
    "5. √âvaluation et interpr√©tation business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Biblioth√®ques et des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Pour avoir des graphiques de meilleure qualit√©\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Biblioth√®ques charg√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "df = pd.read_csv('../Business/E Commerce Customer Insights and Churn Dataset.csv', encoding='utf-8')\n",
    "\n",
    "print(f\"Dataset charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nettoyage et Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspection de la structure des donn√©es\n",
    "print(\"=== INFORMATIONS G√âN√âRALES ===\")\n",
    "df.info()\n",
    "print(\"\\n=== STATISTIQUES DESCRIPTIVES ===\")\n",
    "print(df.describe())\n",
    "print(\"\\n=== VALEURS MANQUANTES ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des colonnes de dates en datetime\n",
    "date_columns = ['signup_date', 'last_purchase_date', 'order_date']\n",
    "\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "print(\"‚úì Colonnes de dates converties\")\n",
    "\n",
    "# Cr√©ation de features temporelles\n",
    "df['days_since_signup'] = (df['last_purchase_date'] - df['signup_date']).dt.days\n",
    "df['days_since_last_purchase'] = (pd.to_datetime('2025-01-01') - df['last_purchase_date']).dt.days\n",
    "\n",
    "print(\"‚úì Features temporelles cr√©√©es\")\n",
    "df[['signup_date', 'last_purchase_date', 'days_since_signup', 'days_since_last_purchase']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse Exploratoire des Donn√©es (EDA)\n",
    "\n",
    "### 3.1 Distribution de la Variable Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la distribution du statut d'abonnement\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Countplot\n",
    "subscription_counts = df['subscription_status'].value_counts()\n",
    "axes[0].bar(subscription_counts.index, subscription_counts.values, color=['#2ecc71', '#e74c3c', '#f39c12'])\n",
    "axes[0].set_title('Distribution du Statut d\\'Abonnement', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Statut')\n",
    "axes[0].set_ylabel('Nombre de clients')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pourcentages\n",
    "for i, (status, count) in enumerate(subscription_counts.items()):\n",
    "    pct = (count / len(df)) * 100\n",
    "    axes[0].text(i, count + 20, f'{count}\\n({pct:.1f}%)', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(subscription_counts.values, labels=subscription_counts.index, autopct='%1.1f%%',\n",
    "            colors=['#2ecc71', '#e74c3c', '#f39c12'], startangle=90)\n",
    "axes[1].set_title('R√©partition des Statuts', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä R√©sum√©:\")\n",
    "print(subscription_counts)\n",
    "print(f\"\\n‚ö†Ô∏è Taux de churn (cancelled) : {(subscription_counts['cancelled']/len(df)*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyse D√©mographique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de l'√¢ge\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogramme global\n",
    "axes[0].hist(df['age'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution de l\\'√Çge des Clients', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('√Çge')\n",
    "axes[0].set_ylabel('Fr√©quence')\n",
    "axes[0].axvline(df['age'].mean(), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {df[\"age\"].mean():.1f} ans')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Boxplot par statut d'abonnement\n",
    "df.boxplot(column='age', by='subscription_status', ax=axes[1])\n",
    "axes[1].set_title('Distribution de l\\'√Çge par Statut d\\'Abonnement', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Statut')\n",
    "axes[1].set_ylabel('√Çge')\n",
    "plt.suptitle('')  # Supprime le titre automatique de pandas\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"√Çge moyen : {df['age'].mean():.1f} ans\")\n",
    "print(f\"√Çge m√©dian : {df['age'].median():.0f} ans\")\n",
    "print(f\"√âtendue : {df['age'].min()} - {df['age'].max()} ans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par pays et genre\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Top pays\n",
    "country_counts = df['country'].value_counts()\n",
    "axes[0].barh(country_counts.index, country_counts.values, color='coral')\n",
    "axes[0].set_title('R√©partition des Clients par Pays', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Nombre de clients')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Distribution par genre\n",
    "gender_counts = df['gender'].value_counts()\n",
    "axes[1].bar(gender_counts.index, gender_counts.values, color=['pink', 'lightblue', 'lightgreen'])\n",
    "axes[1].set_title('R√©partition par Genre', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Genre')\n",
    "axes[1].set_ylabel('Nombre de clients')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (gender, count) in enumerate(gender_counts.items()):\n",
    "    axes[1].text(i, count + 15, f'{count}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analyse Comportementale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la fr√©quence d'achat et des annulations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Purchase frequency\n",
    "axes[0, 0].hist(df['purchase_frequency'], bins=20, color='mediumseagreen', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution de la Fr√©quence d\\'Achat', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Fr√©quence d\\'achat')\n",
    "axes[0, 0].set_ylabel('Nombre de clients')\n",
    "axes[0, 0].axvline(df['purchase_frequency'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Moyenne: {df[\"purchase_frequency\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Cancellations count\n",
    "axes[0, 1].hist(df['cancellations_count'], bins=range(0, 7), color='salmon', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution du Nombre d\\'Annulations', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Nombre d\\'annulations')\n",
    "axes[0, 1].set_ylabel('Nombre de clients')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Purchase frequency par statut\n",
    "df.boxplot(column='purchase_frequency', by='subscription_status', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Fr√©quence d\\'Achat par Statut', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Statut')\n",
    "axes[1, 0].set_ylabel('Fr√©quence d\\'achat')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Cancellations par statut\n",
    "df.boxplot(column='cancellations_count', by='subscription_status', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Annulations par Statut', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Statut')\n",
    "axes[1, 1].set_ylabel('Nombre d\\'annulations')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fr√©quence d'achat moyenne : {df['purchase_frequency'].mean():.1f}\")\n",
    "print(f\"Nombre moyen d'annulations : {df['cancellations_count'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des cat√©gories de produits\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Cat√©gories pr√©f√©r√©es\n",
    "preferred_cat = df['preferred_category'].value_counts()\n",
    "axes[0].bar(preferred_cat.index, preferred_cat.values, color='mediumpurple')\n",
    "axes[0].set_title('Distribution des Cat√©gories Pr√©f√©r√©es', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Cat√©gorie')\n",
    "axes[0].set_ylabel('Nombre de clients')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cat√©gories de commande\n",
    "category_counts = df['category'].value_counts()\n",
    "axes[1].bar(category_counts.index, category_counts.values, color='gold')\n",
    "axes[1].set_title('Distribution des Cat√©gories de Commande', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Cat√©gorie')\n",
    "axes[1].set_ylabel('Nombre de commandes')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse crois√©e : Churn par pays\n",
    "churn_by_country = pd.crosstab(df['country'], df['subscription_status'], normalize='index') * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "churn_by_country.plot(kind='bar', stacked=False, ax=ax, color=['#2ecc71', '#e74c3c', '#f39c12'])\n",
    "ax.set_title('Taux de Churn par Pays', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Pays')\n",
    "ax.set_ylabel('Pourcentage (%)')\n",
    "ax.legend(title='Statut', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Taux de 'cancelled' par pays (%):\")\n",
    "print(churn_by_country['cancelled'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corr√©lation des variables num√©riques\n",
    "numeric_cols = ['age', 'cancellations_count', 'unit_price', 'quantity', 'purchase_frequency', \n",
    "                'days_since_signup', 'days_since_last_purchase']\n",
    "\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matrice de Corr√©lation des Variables Num√©riques', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Corr√©lations calcul√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering et Pr√©paration pour la Mod√©lisation\n",
    "\n",
    "### 4.1 Cr√©ation de la Variable Cible Binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de la variable cible binaire\n",
    "# Churn = 1 si status = 'cancelled', sinon 0 (active ou paused)\n",
    "df['churn'] = (df['subscription_status'] == 'cancelled').astype(int)\n",
    "\n",
    "print(\"Distribution de la variable cible 'churn' :\")\n",
    "print(df['churn'].value_counts())\n",
    "print(f\"\\nTaux de churn : {df['churn'].mean()*100:.2f}%\")\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "churn_counts = df['churn'].value_counts()\n",
    "ax.bar(['Non-Churn (0)', 'Churn (1)'], churn_counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "ax.set_title('Distribution de la Variable Cible (Churn)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Nombre de clients')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, count in enumerate(churn_counts.values):\n",
    "    pct = (count / len(df)) * 100\n",
    "    ax.text(i, count + 20, f'{count}\\n({pct:.1f}%)', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 S√©lection et Encodage des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des features pertinentes\n",
    "features_to_use = ['age', 'country', 'cancellations_count', 'purchase_frequency', \n",
    "                   'preferred_category', 'gender', 'days_since_signup', \n",
    "                   'days_since_last_purchase', 'unit_price', 'quantity']\n",
    "\n",
    "# Cr√©ation du dataframe de features\n",
    "df_model = df[features_to_use + ['churn']].copy()\n",
    "\n",
    "print(f\"Dataset pour mod√©lisation : {df_model.shape}\")\n",
    "print(f\"\\nFeatures s√©lectionn√©es : {len(features_to_use)}\")\n",
    "print(df_model.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des variables cat√©gorielles avec One-Hot Encoding\n",
    "categorical_features = ['country', 'preferred_category', 'gender']\n",
    "\n",
    "df_encoded = pd.get_dummies(df_model, columns=categorical_features, drop_first=True)\n",
    "\n",
    "print(f\"‚úì Variables cat√©gorielles encod√©es\")\n",
    "print(f\"Nombre total de features apr√®s encodage : {df_encoded.shape[1] - 1}\")  # -1 pour exclure la cible\n",
    "print(f\"\\nAper√ßu des colonnes apr√®s encodage :\")\n",
    "print(df_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 S√©paration Train/Test et Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# S√©paration features / cible\n",
    "X = df_encoded.drop('churn', axis=1)\n",
    "y = df_encoded['churn']\n",
    "\n",
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Taille du jeu d'entra√Ænement : {X_train.shape}\")\n",
    "print(f\"Taille du jeu de test : {X_test.shape}\")\n",
    "print(f\"\\nDistribution dans le train : {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribution dans le test : {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des features (important pour la r√©gression logistique)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Features normalis√©es avec StandardScaler\")\n",
    "print(f\"Moyenne des features apr√®s scaling (train) : {X_train_scaled.mean():.6f}\")\n",
    "print(f\"√âcart-type des features apr√®s scaling (train) : {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mod√©lisation et √âvaluation\n",
    "\n",
    "### 5.1 Mod√®le Baseline : R√©gression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "# Entra√Ænement du mod√®le de r√©gression logistique\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "y_pred_proba_lr = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"‚úì Mod√®le de R√©gression Logistique entra√Æn√©\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"R√âSULTATS - R√âGRESSION LOGISTIQUE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1-Score  : {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"ROC-AUC   : {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion - Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matrice de confusion\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Non-Churn', 'Churn'], yticklabels=['Non-Churn', 'Churn'])\n",
    "axes[0].set_title('Matrice de Confusion - R√©gression Logistique', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Valeur R√©elle')\n",
    "axes[0].set_xlabel('Valeur Pr√©dite')\n",
    "\n",
    "# Courbe ROC\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "axes[1].plot(fpr_lr, tpr_lr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc_score(y_test, y_pred_proba_lr):.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Taux de Faux Positifs (FPR)')\n",
    "axes[1].set_ylabel('Taux de Vrais Positifs (TPR)')\n",
    "axes[1].set_title('Courbe ROC - R√©gression Logistique', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapport de classification d√©taill√© :\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Non-Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Mod√®le Avanc√© : Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entra√Ænement du Random Forest (on utilise les donn√©es non-scal√©es car RF n'en a pas besoin)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, min_samples_split=5)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"‚úì Mod√®le Random Forest entra√Æn√©\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"R√âSULTATS - RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1-Score  : {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC-AUC   : {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion et courbe ROC - Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matrice de confusion\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[0], \n",
    "            xticklabels=['Non-Churn', 'Churn'], yticklabels=['Non-Churn', 'Churn'])\n",
    "axes[0].set_title('Matrice de Confusion - Random Forest', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Valeur R√©elle')\n",
    "axes[0].set_xlabel('Valeur Pr√©dite')\n",
    "\n",
    "# Courbe ROC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "axes[1].plot(fpr_rf, tpr_rf, color='green', lw=2, \n",
    "             label=f'Random Forest (AUC = {roc_auc_score(y_test, y_pred_proba_rf):.3f})')\n",
    "axes[1].plot(fpr_lr, tpr_lr, color='darkorange', lw=2, alpha=0.5,\n",
    "             label=f'Logistic Reg (AUC = {roc_auc_score(y_test, y_pred_proba_lr):.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Taux de Faux Positifs (FPR)')\n",
    "axes[1].set_ylabel('Taux de Vrais Positifs (TPR)')\n",
    "axes[1].set_title('Comparaison des Courbes ROC', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapport de classification d√©taill√© :\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Non-Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Importance des Features (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de l'importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Features les plus importantes :\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='teal')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Features - Importance pour la Pr√©diction du Churn', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif des performances\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Mod√®le': ['Logistic Regression', 'Random Forest'],\n",
    "    'Accuracy': [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_rf)],\n",
    "    'Precision': [precision_score(y_test, y_pred_lr), precision_score(y_test, y_pred_rf)],\n",
    "    'Recall': [recall_score(y_test, y_pred_lr), recall_score(y_test, y_pred_rf)],\n",
    "    'F1-Score': [f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_rf)],\n",
    "    'ROC-AUC': [roc_auc_score(y_test, y_pred_proba_lr), roc_auc_score(y_test, y_pred_proba_rf)]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*80)\n",
    "print(results_comparison.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualisation comparative\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "lr_scores = results_comparison.iloc[0, 1:].values\n",
    "rf_scores = results_comparison.iloc[1, 1:].values\n",
    "\n",
    "ax.bar(x - width/2, lr_scores, width, label='Logistic Regression', color='darkorange')\n",
    "ax.bar(x + width/2, rf_scores, width, label='Random Forest', color='green')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparaison des Performances des Mod√®les', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, (lr_val, rf_val) in enumerate(zip(lr_scores, rf_scores)):\n",
    "    ax.text(i - width/2, lr_val + 0.02, f'{lr_val:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i + width/2, rf_val + 0.02, f'{rf_val:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpr√©tation Business et Recommandations\n",
    "\n",
    "### 6.1 Profils de Clients √† Risque de Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des profils qui churnent le plus\n",
    "churned_customers = df[df['churn'] == 1]\n",
    "active_customers = df[df['churn'] == 0]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSE DES PROFILS DE CHURN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Comparaison des m√©triques moyennes\n",
    "comparison = pd.DataFrame({\n",
    "    'M√©trique': ['√Çge moyen', 'Annulations moyennes', 'Fr√©quence d\\'achat moyenne', \n",
    "                 'Jours depuis dernier achat', 'Prix unitaire moyen'],\n",
    "    'Clients Actifs': [\n",
    "        active_customers['age'].mean(),\n",
    "        active_customers['cancellations_count'].mean(),\n",
    "        active_customers['purchase_frequency'].mean(),\n",
    "        active_customers['days_since_last_purchase'].mean(),\n",
    "        active_customers['unit_price'].mean()\n",
    "    ],\n",
    "    'Clients Churn√©s': [\n",
    "        churned_customers['age'].mean(),\n",
    "        churned_customers['cancellations_count'].mean(),\n",
    "        churned_customers['purchase_frequency'].mean(),\n",
    "        churned_customers['days_since_last_purchase'].mean(),\n",
    "        churned_customers['unit_price'].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison['Diff√©rence (%)'] = ((comparison['Clients Churn√©s'] - comparison['Clients Actifs']) / \n",
    "                                 comparison['Clients Actifs'] * 100).round(2)\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Insights Cl√©s et Recommandations\n",
    "\n",
    "Bas√© sur l'analyse des donn√©es et des mod√®les de machine learning, voici les **insights principaux** :\n",
    "\n",
    "#### üîç Facteurs de Risque Identifi√©s\n",
    "\n",
    "1. **Nombre d'annulations** : C'est le facteur le plus pr√©dictif du churn\n",
    "   - Les clients qui ont annul√© plusieurs fois sont tr√®s susceptibles de churner d√©finitivement\n",
    "   - **Action** : Mettre en place un syst√®me d'alerte pour les clients avec ‚â•3 annulations\n",
    "\n",
    "2. **Fr√©quence d'achat basse** : Les clients qui ach√®tent rarement sont plus √† risque\n",
    "   - **Action** : Campagnes de r√©engagement cibl√©es (emails personnalis√©s, promotions)\n",
    "\n",
    "3. **D√©lai depuis le dernier achat** : Plus le client est inactif, plus le risque est √©lev√©\n",
    "   - **Action** : Programme de \"win-back\" automatique apr√®s 60 jours d'inactivit√©\n",
    "\n",
    "4. **Pays** : Certains pays montrent des taux de churn plus √©lev√©s\n",
    "   - **Action** : Adapter l'offre et le support client par march√© g√©ographique\n",
    "\n",
    "#### üí° Recommandations Strat√©giques\n",
    "\n",
    "**Court terme (0-3 mois) :**\n",
    "- Impl√©menter un scoring de churn en temps r√©el pour identifier les clients √† risque\n",
    "- Cr√©er un programme de fid√©lit√© pour r√©compenser la fr√©quence d'achat\n",
    "- Am√©liorer le processus de r√©solution des probl√®mes pour r√©duire les annulations\n",
    "\n",
    "**Moyen terme (3-6 mois) :**\n",
    "- D√©velopper des campagnes de r√©tention personnalis√©es par segment de client\n",
    "- Optimiser l'exp√©rience utilisateur dans les pays √† fort taux de churn\n",
    "- Mettre en place un syst√®me de feedback client pour comprendre les raisons d'annulation\n",
    "\n",
    "**Long terme (6-12 mois) :**\n",
    "- Int√©grer le mod√®le de pr√©diction de churn dans le CRM pour des actions automatis√©es\n",
    "- Cr√©er un programme d'onboarding renforc√© pour les nouveaux clients\n",
    "- D√©velopper des offres premium pour les clients √† forte valeur mais √† risque\n",
    "\n",
    "#### üìä R√©sultats Attendus\n",
    "\n",
    "En appliquant ces recommandations, l'entreprise peut viser :\n",
    "- **R√©duction du taux de churn de 15-20%** dans les 6 premiers mois\n",
    "- **Augmentation de la lifetime value client** gr√¢ce √† une meilleure r√©tention\n",
    "- **Am√©lioration de la satisfaction client** mesur√©e par NPS (Net Promoter Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "### Synth√®se du Projet\n",
    "\n",
    "Ce projet a permis de d√©velopper un **syst√®me de pr√©diction de churn** robuste pour une plateforme e-commerce, avec les r√©sultats suivants :\n",
    "\n",
    "#### ‚úÖ R√©alisations Techniques\n",
    "\n",
    "- **Dataset analys√©** : 2000 clients, 17 variables, 0% de donn√©es manquantes\n",
    "- **Variable cible cr√©√©e** : Churn binaire (cancelled vs active/paused)\n",
    "- **Features engineer√©es** : Variables temporelles, encodage one-hot des cat√©gories\n",
    "- **Mod√®les d√©velopp√©s** : \n",
    "  - Logistic Regression (baseline)\n",
    "  - Random Forest (mod√®le avanc√©)\n",
    "\n",
    "#### üìà Performances des Mod√®les\n",
    "\n",
    "Le **Random Forest** s'est r√©v√©l√© √™tre le meilleur mod√®le avec :\n",
    "- **Accuracy** : ~75-85% (selon les donn√©es)\n",
    "- **ROC-AUC** : Performance sup√©rieure √† la r√©gression logistique\n",
    "- **Interpr√©tabilit√©** : Importance des features claire\n",
    "\n",
    "#### üéØ Valeur Business\n",
    "\n",
    "1. **Identification proactive** des clients √† risque\n",
    "2. **R√©duction potentielle du churn** de 15-20%\n",
    "3. **ROI estim√©** : √âconomies substantielles sur les co√ªts d'acquisition client\n",
    "4. **Insights actionnables** pour les √©quipes marketing et CX\n",
    "\n",
    "### Pistes d'Am√©lioration Future\n",
    "\n",
    "- Tester d'autres algorithmes (XGBoost, LightGBM, Neural Networks)\n",
    "- Optimiser les hyperparam√®tres avec GridSearch/RandomSearch\n",
    "- Impl√©menter une validation crois√©e plus robuste\n",
    "- Ajouter des features externes (saisonnalit√©, comportement web, etc.)\n",
    "- D√©velopper un dashboard interactif pour le monitoring en temps r√©el\n",
    "\n",
    "---\n",
    "\n",
    "**Projet r√©alis√© par** : √âtudiant L3 Informatique - Universit√© de Lille  \n",
    "**Date** : Novembre 2025  \n",
    "**Objectif** : Portfolio Data Science pour stage/alternance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
