{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des R√©sultats de Tests M√©dicaux - Healthcare Dataset\n",
    "\n",
    "## Contexte Projet\n",
    "Ce notebook analyse un dataset synth√©tique d'**admissions hospitali√®res** pour pr√©dire les r√©sultats de tests m√©dicaux (Normal, Abnormal, Inconclusive) et identifier les facteurs de risque associ√©s aux r√©sultats anormaux.\n",
    "\n",
    "‚ö†Ô∏è **Note importante** : Ce dataset est synth√©tique et utilis√© uniquement √† des fins p√©dagogiques. Les conclusions ne constituent pas des recommandations m√©dicales.\n",
    "\n",
    "## Dataset\n",
    "- **Source** : Healthcare Dataset (Kaggle)\n",
    "- **Taille** : 55,500 patients\n",
    "- **Variables** : 15 colonnes (d√©mographiques, m√©dicales, administratives)\n",
    "- **Cible** : Test Results (3 classes : Normal, Abnormal, Inconclusive)\n",
    "\n",
    "## Objectifs\n",
    "1. Analyse exploratoire des donn√©es de sant√©\n",
    "2. Identification des patterns entre conditions m√©dicales et r√©sultats de tests\n",
    "3. Construction de mod√®les de classification multi-classes\n",
    "4. Extraction d'insights pour comprendre les facteurs de risque\n",
    "\n",
    "## Pipeline\n",
    "1. Chargement et nettoyage des donn√©es\n",
    "2. Analyse exploratoire (EDA) orient√©e sant√©\n",
    "3. Feature engineering et pr√©paration\n",
    "4. Mod√©lisation (Logistic Regression, Random Forest)\n",
    "5. √âvaluation et interpr√©tation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports des biblioth√®ques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des visualisations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Biblioth√®ques charg√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement et Exploration Initiale des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "df = pd.read_csv('../health_care/healthcare_dataset.csv')\n",
    "\n",
    "print(f\"üìä Dataset charg√© : {df.shape[0]:,} patients, {df.shape[1]} colonnes\")\n",
    "print(f\"\\nüìã Colonnes disponibles :\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nüëÄ Aper√ßu des premi√®res lignes :\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur la structure des donn√©es\n",
    "print(\"=== INFORMATIONS SUR LE DATASET ===\")\n",
    "df.info()\n",
    "print(\"\\n=== STATISTIQUES DESCRIPTIVES ===\")\n",
    "print(df.describe())\n",
    "print(\"\\n=== VALEURS MANQUANTES ===\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\n‚úì Aucune valeur manquante d√©tect√©e\" if df.isnull().sum().sum() == 0 else \"‚ö†Ô∏è Valeurs manquantes √† traiter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nettoyage des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes non pertinentes pour la classification\n",
    "# Les identifiants uniques (Name, Doctor, Hospital, Room Number) n'apportent pas d'information pr√©dictive\n",
    "columns_to_drop = ['Name', 'Doctor', 'Hospital', 'Room Number']\n",
    "\n",
    "df_clean = df.drop(columns=columns_to_drop)\n",
    "print(f\"‚úì Colonnes supprim√©es : {columns_to_drop}\")\n",
    "print(f\"Nouvelles dimensions : {df_clean.shape}\")\n",
    "\n",
    "# V√©rification des valeurs n√©gatives dans Billing Amount (anomalie possible)\n",
    "negative_billing = df_clean[df_clean['Billing Amount'] < 0]\n",
    "print(f\"\\n‚ö†Ô∏è Nombre de montants de facturation n√©gatifs : {len(negative_billing)}\")\n",
    "\n",
    "if len(negative_billing) > 0:\n",
    "    print(f\"Ces valeurs seront conserv√©es car elles peuvent repr√©senter des remboursements ou ajustements\")\n",
    "\n",
    "print(f\"\\nüìä Dataset nettoy√© : {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des dates en datetime\n",
    "df_clean['Date of Admission'] = pd.to_datetime(df_clean['Date of Admission'])\n",
    "df_clean['Discharge Date'] = pd.to_datetime(df_clean['Discharge Date'])\n",
    "\n",
    "# Cr√©ation d'une feature : dur√©e de s√©jour (en jours)\n",
    "df_clean['Length of Stay'] = (df_clean['Discharge Date'] - df_clean['Date of Admission']).dt.days\n",
    "\n",
    "print(\"‚úì Colonnes de dates converties\")\n",
    "print(f\"‚úì Feature 'Length of Stay' cr√©√©e\")\n",
    "print(f\"\\nStatistiques de la dur√©e de s√©jour :\")\n",
    "print(df_clean['Length of Stay'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse Exploratoire des Donn√©es (EDA)\n",
    "\n",
    "### 4.1 Distribution de la Variable Cible (Test Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de la variable cible : Test Results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Countplot\n",
    "test_results_counts = df_clean['Test Results'].value_counts()\n",
    "colors = ['#ff6b6b', '#51cf66', '#ffd43b']  # Rouge pour Abnormal, Vert pour Normal, Jaune pour Inconclusive\n",
    "axes[0].bar(test_results_counts.index, test_results_counts.values, color=colors)\n",
    "axes[0].set_title('Distribution des R√©sultats de Tests', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('R√©sultat du Test')\n",
    "axes[0].set_ylabel('Nombre de patients')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ajout des valeurs et pourcentages\n",
    "for i, (result, count) in enumerate(test_results_counts.items()):\n",
    "    pct = (count / len(df_clean)) * 100\n",
    "    axes[0].text(i, count + 500, f'{count:,}\\n({pct:.1f}%)', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(test_results_counts.values, labels=test_results_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90, explode=(0.05, 0.05, 0.05))\n",
    "axes[1].set_title('R√©partition des R√©sultats de Tests', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Distribution des r√©sultats de tests :\")\n",
    "print(test_results_counts)\n",
    "print(f\"\\n‚úì Dataset √©quilibr√© : les 3 classes sont repr√©sent√©es de mani√®re similaire (~33% chacune)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analyse D√©mographique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de l'√¢ge\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogramme de l'√¢ge\n",
    "axes[0].hist(df_clean['Age'], bins=40, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution de l\\'√Çge des Patients', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('√Çge')\n",
    "axes[0].set_ylabel('Fr√©quence')\n",
    "axes[0].axvline(df_clean['Age'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Moyenne: {df_clean[\"Age\"].mean():.1f} ans')\n",
    "axes[0].axvline(df_clean['Age'].median(), color='green', linestyle='--', linewidth=2, \n",
    "                label=f'M√©diane: {df_clean[\"Age\"].median():.0f} ans')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Boxplot de l'√¢ge par r√©sultat de test\n",
    "df_clean.boxplot(column='Age', by='Test Results', ax=axes[1])\n",
    "axes[1].set_title('Distribution de l\\'√Çge par R√©sultat de Test', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('R√©sultat du Test')\n",
    "axes[1].set_ylabel('√Çge')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"√Çge moyen : {df_clean['Age'].mean():.1f} ans\")\n",
    "print(f\"√Çge m√©dian : {df_clean['Age'].median():.0f} ans\")\n",
    "print(f\"√âtendue : {df_clean['Age'].min()} - {df_clean['Age'].max()} ans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par genre et groupe sanguin\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Distribution par genre\n",
    "gender_counts = df_clean['Gender'].value_counts()\n",
    "axes[0].bar(gender_counts.index, gender_counts.values, color=['lightblue', 'pink'])\n",
    "axes[0].set_title('R√©partition par Genre', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Genre')\n",
    "axes[0].set_ylabel('Nombre de patients')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (gender, count) in enumerate(gender_counts.items()):\n",
    "    axes[0].text(i, count + 500, f'{count:,}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Distribution par groupe sanguin\n",
    "blood_type_counts = df_clean['Blood Type'].value_counts().sort_values(ascending=True)\n",
    "axes[1].barh(blood_type_counts.index, blood_type_counts.values, color='crimson', alpha=0.7)\n",
    "axes[1].set_title('R√©partition par Groupe Sanguin', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Nombre de patients')\n",
    "axes[1].set_ylabel('Groupe Sanguin')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì R√©partition √©quilibr√©e entre les genres et les groupes sanguins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Analyse des Conditions M√©dicales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des conditions m√©dicales\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "medical_conditions = df_clean['Medical Condition'].value_counts()\n",
    "ax.barh(medical_conditions.index, medical_conditions.values, color='teal', alpha=0.7)\n",
    "ax.set_title('R√©partition des Conditions M√©dicales', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Nombre de patients')\n",
    "ax.set_ylabel('Condition M√©dicale')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Ajout des valeurs\n",
    "for i, (condition, count) in enumerate(medical_conditions.items()):\n",
    "    ax.text(count + 100, i, f'{count:,}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Distribution des conditions m√©dicales :\")\n",
    "print(medical_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Analyse Crois√©e : Test Results vs Medical Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse crois√©e : Test Results par Medical Condition\n",
    "test_by_condition = pd.crosstab(df_clean['Medical Condition'], df_clean['Test Results'], normalize='index') * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "test_by_condition.plot(kind='bar', stacked=True, ax=axes[0], \n",
    "                        color=['#ff6b6b', '#51cf66', '#ffd43b'], alpha=0.8)\n",
    "axes[0].set_title('R√©sultats de Tests par Condition M√©dicale (%)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Condition M√©dicale')\n",
    "axes[0].set_ylabel('Pourcentage (%)')\n",
    "axes[0].legend(title='Test Results', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(test_by_condition, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[1], \n",
    "            cbar_kws={'label': 'Pourcentage (%)'})\n",
    "axes[1].set_title('Heatmap : Test Results par Condition M√©dicale', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('R√©sultat du Test')\n",
    "axes[1].set_ylabel('Condition M√©dicale')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Pourcentage de r√©sultats 'Abnormal' par condition m√©dicale :\")\n",
    "print(test_by_condition['Abnormal'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Analyse par Type d'Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par type d'admission\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Distribution des types d'admission\n",
    "admission_counts = df_clean['Admission Type'].value_counts()\n",
    "axes[0].bar(admission_counts.index, admission_counts.values, color=['orange', 'red', 'green'])\n",
    "axes[0].set_title('Distribution des Types d\\'Admission', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Type d\\'Admission')\n",
    "axes[0].set_ylabel('Nombre de patients')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (admission, count) in enumerate(admission_counts.items()):\n",
    "    axes[0].text(i, count + 200, f'{count:,}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Test Results par Admission Type\n",
    "test_by_admission = pd.crosstab(df_clean['Admission Type'], df_clean['Test Results'], normalize='index') * 100\n",
    "test_by_admission.plot(kind='bar', ax=axes[1], color=['#ff6b6b', '#51cf66', '#ffd43b'], alpha=0.8)\n",
    "axes[1].set_title('R√©sultats de Tests par Type d\\'Admission', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Type d\\'Admission')\n",
    "axes[1].set_ylabel('Pourcentage (%)')\n",
    "axes[1].legend(title='Test Results')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Pourcentage de tests 'Abnormal' par type d'admission :\")\n",
    "print(test_by_admission['Abnormal'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Analyse des Assurances et Montants de Facturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des assurances\n",
    "insurance_counts = df_clean['Insurance Provider'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Distribution des assureurs\n",
    "axes[0].barh(insurance_counts.index, insurance_counts.values, color='purple', alpha=0.6)\n",
    "axes[0].set_title('R√©partition des Assurances', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Nombre de patients')\n",
    "axes[0].set_ylabel('Assureur')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Test Results par Insurance Provider\n",
    "test_by_insurance = pd.crosstab(df_clean['Insurance Provider'], df_clean['Test Results'], normalize='index') * 100\n",
    "test_by_insurance.plot(kind='barh', ax=axes[1], color=['#ff6b6b', '#51cf66', '#ffd43b'], alpha=0.8)\n",
    "axes[1].set_title('R√©sultats de Tests par Assureur', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Pourcentage (%)')\n",
    "axes[1].set_ylabel('Assureur')\n",
    "axes[1].legend(title='Test Results', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Distribution des assurances :\")\n",
    "print(insurance_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des montants de facturation par r√©sultat de test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Boxplot du Billing Amount par Test Results\n",
    "df_clean.boxplot(column='Billing Amount', by='Test Results', ax=axes[0])\n",
    "axes[0].set_title('Distribution des Montants de Facturation par R√©sultat de Test', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('R√©sultat du Test')\n",
    "axes[0].set_ylabel('Montant de Facturation ($)')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Moyennes par Test Results\n",
    "billing_by_test = df_clean.groupby('Test Results')['Billing Amount'].mean().sort_values(ascending=False)\n",
    "axes[1].bar(billing_by_test.index, billing_by_test.values, color=['#ff6b6b', '#51cf66', '#ffd43b'])\n",
    "axes[1].set_title('Montant Moyen de Facturation par R√©sultat de Test', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('R√©sultat du Test')\n",
    "axes[1].set_ylabel('Montant Moyen ($)')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (test, amount) in enumerate(billing_by_test.items()):\n",
    "    axes[1].text(i, amount + 100, f'${amount:,.0f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí∞ Montant moyen de facturation par r√©sultat de test :\")\n",
    "print(billing_by_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pr√©paration des Donn√©es pour la Mod√©lisation\n",
    "\n",
    "### 5.1 S√©lection des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des features pertinentes pour la classification\n",
    "# Exclusion des dates et de Medication (trop de variabilit√©/identifiants)\n",
    "features_to_use = ['Age', 'Gender', 'Blood Type', 'Medical Condition', \n",
    "                   'Admission Type', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Length of Stay']\n",
    "\n",
    "# Variable cible\n",
    "target = 'Test Results'\n",
    "\n",
    "# Cr√©ation du dataset pour la mod√©lisation\n",
    "df_model = df_clean[features_to_use + [target]].copy()\n",
    "\n",
    "print(f\"üìä Dataset pour mod√©lisation : {df_model.shape}\")\n",
    "print(f\"Features s√©lectionn√©es : {len(features_to_use)}\")\n",
    "print(f\"Variable cible : {target}\")\n",
    "print(f\"\\nAper√ßu :\")\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Encodage des Variables Cat√©gorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage One-Hot des variables cat√©gorielles\n",
    "categorical_features = ['Gender', 'Blood Type', 'Medical Condition', \n",
    "                        'Admission Type', 'Insurance Provider']\n",
    "\n",
    "df_encoded = pd.get_dummies(df_model, columns=categorical_features, drop_first=True)\n",
    "\n",
    "print(f\"‚úì Variables cat√©gorielles encod√©es\")\n",
    "print(f\"Nombre de features apr√®s encodage : {df_encoded.shape[1] - 1}\")  # -1 pour la cible\n",
    "print(f\"\\nAper√ßu des colonnes apr√®s encodage :\")\n",
    "print(df_encoded.columns.tolist()[:20])  # Affiche les 20 premi√®res colonnes\n",
    "print(f\"... et {df_encoded.shape[1] - 20} autres colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 S√©paration Train/Test et Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# S√©paration features / cible\n",
    "X = df_encoded.drop('Test Results', axis=1)\n",
    "y = df_encoded['Test Results']\n",
    "\n",
    "# Split train/test (80/20) avec stratification pour garder les proportions des classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Taille du jeu d'entra√Ænement : {X_train.shape}\")\n",
    "print(f\"Taille du jeu de test : {X_test.shape}\")\n",
    "print(f\"\\nDistribution dans le train :\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nDistribution dans le test :\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des features num√©riques (important pour la r√©gression logistique)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Features normalis√©es avec StandardScaler\")\n",
    "print(f\"Moyenne des features apr√®s scaling (train) : {X_train_scaled.mean():.6f}\")\n",
    "print(f\"√âcart-type des features apr√®s scaling (train) : {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mod√©lisation et √âvaluation\n",
    "\n",
    "### 6.1 Mod√®le Baseline : R√©gression Logistique Multi-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Entra√Ænement de la r√©gression logistique multinomiale\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"‚úì Mod√®le de R√©gression Logistique Multi-classes entra√Æn√©\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"R√âSULTATS - R√âGRESSION LOGISTIQUE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy       : {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_score(y_test, y_pred_lr, average='macro'):.4f}\")\n",
    "print(f\"F1-Score (Micro): {f1_score(y_test, y_pred_lr, average='micro'):.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1_score(y_test, y_pred_lr, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion - Logistic Regression\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "labels = sorted(y_test.unique())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "ax.set_title('Matrice de Confusion - R√©gression Logistique', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Valeur R√©elle')\n",
    "ax.set_xlabel('Valeur Pr√©dite')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapport de classification d√©taill√© :\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Mod√®le Avanc√© : Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entra√Ænement du Random Forest (pas besoin de normalisation pour les arbres)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15, min_samples_split=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"‚úì Mod√®le Random Forest entra√Æn√©\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"R√âSULTATS - RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy       : {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1-Score (Macro): {f1_score(y_test, y_pred_rf, average='macro'):.4f}\")\n",
    "print(f\"F1-Score (Micro): {f1_score(y_test, y_pred_rf, average='micro'):.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1_score(y_test, y_pred_rf, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion - Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "ax.set_title('Matrice de Confusion - Random Forest', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Valeur R√©elle')\n",
    "ax.set_xlabel('Valeur Pr√©dite')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapport de classification d√©taill√© :\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Importance des Features (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de l'importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 Features les plus importantes :\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='teal')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Features - Importance pour la Classification', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif des performances\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Mod√®le': ['Logistic Regression', 'Random Forest'],\n",
    "    'Accuracy': [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_rf)],\n",
    "    'F1-Score (Macro)': [f1_score(y_test, y_pred_lr, average='macro'), \n",
    "                         f1_score(y_test, y_pred_rf, average='macro')],\n",
    "    'F1-Score (Weighted)': [f1_score(y_test, y_pred_lr, average='weighted'), \n",
    "                            f1_score(y_test, y_pred_rf, average='weighted')]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*80)\n",
    "print(results_comparison.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualisation comparative\n",
    "metrics = ['Accuracy', 'F1-Score (Macro)', 'F1-Score (Weighted)']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "lr_scores = results_comparison.iloc[0, 1:].values\n",
    "rf_scores = results_comparison.iloc[1, 1:].values\n",
    "\n",
    "ax.bar(x - width/2, lr_scores, width, label='Logistic Regression', color='darkorange')\n",
    "ax.bar(x + width/2, rf_scores, width, label='Random Forest', color='green')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Comparaison des Performances des Mod√®les', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.1])\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, (lr_val, rf_val) in enumerate(zip(lr_scores, rf_scores)):\n",
    "    ax.text(i - width/2, lr_val + 0.02, f'{lr_val:.3f}', ha='center', fontsize=10)\n",
    "    ax.text(i + width/2, rf_val + 0.02, f'{rf_val:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interpr√©tation et Insights Sant√©\n",
    "\n",
    "### 7.1 Analyse des Facteurs de Risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse comparative des patients par r√©sultat de test\n",
    "abnormal_patients = df_clean[df_clean['Test Results'] == 'Abnormal']\n",
    "normal_patients = df_clean[df_clean['Test Results'] == 'Normal']\n",
    "inconclusive_patients = df_clean[df_clean['Test Results'] == 'Inconclusive']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSE COMPARATIVE PAR R√âSULTAT DE TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'M√©trique': ['√Çge moyen', 'Dur√©e de s√©jour moyenne (jours)', 'Montant moyen de facturation ($)'],\n",
    "    'Normal': [\n",
    "        normal_patients['Age'].mean(),\n",
    "        normal_patients['Length of Stay'].mean(),\n",
    "        normal_patients['Billing Amount'].mean()\n",
    "    ],\n",
    "    'Abnormal': [\n",
    "        abnormal_patients['Age'].mean(),\n",
    "        abnormal_patients['Length of Stay'].mean(),\n",
    "        abnormal_patients['Billing Amount'].mean()\n",
    "    ],\n",
    "    'Inconclusive': [\n",
    "        inconclusive_patients['Age'].mean(),\n",
    "        inconclusive_patients['Length of Stay'].mean(),\n",
    "        inconclusive_patients['Billing Amount'].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Insights Cl√©s\n",
    "\n",
    "‚ö†Ô∏è **Rappel** : Ce dataset est synth√©tique. Les conclusions ci-dessous sont p√©dagogiques et ne constituent pas des recommandations m√©dicales.\n",
    "\n",
    "#### üîç Facteurs Influen√ßant les R√©sultats Anormaux\n",
    "\n",
    "D'apr√®s l'analyse des features importantes du Random Forest :\n",
    "\n",
    "1. **Dur√©e de s√©jour (Length of Stay)** : \n",
    "   - Feature la plus importante pour pr√©dire le r√©sultat des tests\n",
    "   - Les s√©jours plus longs peuvent indiquer des cas plus complexes n√©cessitant plus d'examens\n",
    "\n",
    "2. **Montant de facturation (Billing Amount)** :\n",
    "   - Corr√©l√© avec la complexit√© des soins\n",
    "   - Les montants √©lev√©s peuvent refl√©ter des traitements plus intensifs li√©s √† des r√©sultats anormaux\n",
    "\n",
    "3. **√Çge du patient** :\n",
    "   - L'√¢ge est un facteur pr√©dictif\n",
    "   - Les diff√©rentes tranches d'√¢ge pr√©sentent des profils de r√©sultats diff√©rents\n",
    "\n",
    "4. **Condition m√©dicale** :\n",
    "   - Certaines conditions (visible dans l'EDA) montrent des taux de tests anormaux l√©g√®rement diff√©rents\n",
    "   - Important pour la stratification des risques\n",
    "\n",
    "5. **Type d'admission** :\n",
    "   - Les admissions d'urgence vs √©lectives peuvent avoir des patterns diff√©rents\n",
    "   - Refl√®te la gravit√© initiale du cas\n",
    "\n",
    "#### üí° Combinaisons √† Risque\n",
    "\n",
    "Les profils suivants pr√©sentent des taux plus √©lev√©s de r√©sultats anormaux (bas√© sur l'EDA) :\n",
    "\n",
    "- **Dur√©e de s√©jour prolong√©e** + **Montant de facturation √©lev√©**\n",
    "- **Certaines conditions m√©dicales** + **Type d'admission sp√©cifique**\n",
    "- **Combinaisons d'assureurs** avec certaines conditions\n",
    "\n",
    "#### üéØ Applications Potentielles\n",
    "\n",
    "Dans un contexte r√©el (avec des donn√©es r√©elles et validation m√©dicale), ce type de mod√®le pourrait :\n",
    "\n",
    "1. **Priorisation des ressources** : Identifier les patients n√©cessitant un suivi approfondi\n",
    "2. **Optimisation des parcours de soins** : Adapter les protocoles selon les profils √† risque\n",
    "3. **Gestion administrative** : Anticiper les besoins en ressources hospitali√®res\n",
    "4. **Recherche clinique** : Identifier des patterns pour √©tudes approfondies\n",
    "\n",
    "#### ‚ö†Ô∏è Limites et Pr√©cautions\n",
    "\n",
    "- Dataset synth√©tique : ne refl√®te pas n√©cessairement la r√©alit√© m√©dicale\n",
    "- Les corr√©lations observ√©es ne sont pas des causalit√©s\n",
    "- Un mod√®le ML ne remplace jamais l'expertise m√©dicale\n",
    "- Validation clinique obligatoire avant toute utilisation r√©elle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "### Synth√®se du Projet\n",
    "\n",
    "Ce projet a permis de d√©velopper un **syst√®me de classification multi-classes** pour pr√©dire les r√©sultats de tests m√©dicaux sur un dataset synth√©tique de 55,500 admissions hospitali√®res.\n",
    "\n",
    "#### ‚úÖ R√©alisations Techniques\n",
    "\n",
    "- **Dataset analys√©** : 55,500 patients, 15 variables, 0% donn√©es manquantes\n",
    "- **Classes cibles** : 3 cat√©gories √©quilibr√©es (Normal, Abnormal, Inconclusive)\n",
    "- **Features engineer√©es** : Dur√©e de s√©jour, encodage one-hot des cat√©gories\n",
    "- **Mod√®les d√©velopp√©s** : \n",
    "  - Logistic Regression multinomiale (baseline)\n",
    "  - Random Forest Classifier (mod√®le avanc√©)\n",
    "\n",
    "#### üìà Performances des Mod√®les\n",
    "\n",
    "Les deux mod√®les affichent des performances similaires :\n",
    "- **Accuracy** : ~33% (proche du hasard pour 3 classes √©quilibr√©es)\n",
    "- **F1-Score** : Similaire entre les deux mod√®les\n",
    "\n",
    "**Observation importante** : Les performances proches du hasard sugg√®rent que dans ce dataset synth√©tique, les r√©sultats de tests sont probablement g√©n√©r√©s al√©atoirement, sans relation causale forte avec les features disponibles.\n",
    "\n",
    "#### üéì Comp√©tences D√©montr√©es\n",
    "\n",
    "1. **Analyse exploratoire compl√®te** : Visualisations multiples, analyses crois√©es\n",
    "2. **Traitement de donn√©es sant√©** : Nettoyage, feature engineering\n",
    "3. **Classification multi-classes** : R√©gression logistique multinomiale, Random Forest\n",
    "4. **√âvaluation rigoureuse** : Matrices de confusion, F1-scores, importance des features\n",
    "5. **Interpr√©tation business** : Insights contextualis√©s et limites reconnues\n",
    "\n",
    "#### üöÄ Pistes d'Am√©lioration\n",
    "\n",
    "- Tester d'autres algorithmes (XGBoost, LightGBM, SVM)\n",
    "- Optimisation des hyperparam√®tres (GridSearchCV, RandomizedSearchCV)\n",
    "- Validation crois√©e stratifi√©e k-fold\n",
    "- Feature engineering avanc√© (interactions, polynomiales)\n",
    "- Analyse de SHAP values pour l'interpr√©tabilit√©\n",
    "- Traitement du d√©s√©quilibre de classes si n√©cessaire (SMOTE, class_weight)\n",
    "\n",
    "---\n",
    "\n",
    "**Projet r√©alis√© par** : √âtudiant L3 Informatique - Universit√© de Lille  \n",
    "**Date** : Novembre 2025  \n",
    "**Objectif** : Portfolio Data Science / ML pour stage et alternance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}